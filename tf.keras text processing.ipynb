{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU版本 指定在CPU上运行\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## panda数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"/home/xm/jupyterwork/univeral-sentence-encoder/ag_news_csv/train.csv\",header=None,usecols=[1,2])\n",
    "train_labels=pd.read_csv(\"/home/xm/jupyterwork/univeral-sentence-encoder/ag_news_csv/train.csv\",header=None,usecols=[0])\n",
    "test_data=pd.read_csv(\"/home/xm/jupyterwork/univeral-sentence-encoder/ag_news_csv/test.csv\",header=None,usecols=[1,2])\n",
    "test_labels=pd.read_csv(\"/home/xm/jupyterwork/univeral-sentence-encoder/ag_news_csv/test.csv\",header=None,usecols=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## titlte+description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array\n",
    "train_data=train_data.values\n",
    "y_train=train_labels.values\n",
    "test_data=test_data.values\n",
    "y_test=test_labels.values\n",
    "\n",
    "train_messages = [None]*120000\n",
    "test_messages = [None]*7600\n",
    "\n",
    "for index, data in enumerate(train_data):\n",
    "    train_messages[index] = data[0]+'.'+data[1]\n",
    "\n",
    "for index, data in enumerate(test_data):\n",
    "    test_messages[index] = data[0]+'.'+data[1]\n",
    "    \n",
    "for index,data in enumerate(y_train):\n",
    "    y_train[index][0]=data[0]-1\n",
    "for index,data in enumerate(y_test):\n",
    "    y_test[index][0]=data[0]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer词典 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', \n",
    "                                   lower=True, split=' ', \n",
    "                                   char_level=False, \n",
    "                                   oov_token=None)\n",
    "tokenizer.fit_on_texts(train_messages)#词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print( 'word_counts:',tokenizer.word_counts) #单词出现次数\n",
    "#print( '\\nword_index:',tokenizer.word_index) #单词出现的位置\n",
    "#print( '\\nword_docs:',tokenizer.word_docs) #单词出现在的文档（行）数\n",
    "#print( '\\nindex_docs',tokenizer.index_docs) #word_index：word_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "70344\n"
     ]
    }
   ],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_messages)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_messages)\n",
    "maxlen=0\n",
    "max_index=0\n",
    "for i, seq in enumerate(train_sequences):\n",
    "    if len(seq)>maxlen:\n",
    "        maxlen=len(seq)\n",
    "    if max(seq)>max_index:\n",
    "        max_index=max(seq)\n",
    "print(maxlen)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  4049,   797,   332],\n",
       "       [    0,     0,     0, ...,     4,     1,   128],\n",
       "       [    0,     0,     0, ...,     1,  1214, 14993],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,   346,    65,   123],\n",
       "       [    0,     0,     0, ...,    42,    16,  1666],\n",
       "       [    0,     0,     0, ...,  2095,  3435,    72]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen)\n",
    "test_x = keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen)\n",
    "y_train_labels = keras.utils.to_categorical(y_train, num_classes=4)\n",
    "y_test_labels = keras.utils.to_categorical(y_test, num_classes=4)\n",
    "train_x\n",
    "#print( tokenizer.texts_to_matrix(test_messages))  # 矩阵化=one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_cnn_model(y,max_features,embedding_dims,filters):\n",
    "    kernel_size = 3\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Embedding(max_features, embedding_dims)) # 使用Embedding层将每个词编码转换为词向量(10000,181,128)\n",
    "    model.add(keras.layers.Conv1D(filters,\n",
    "                     kernel_size,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    # 池化\n",
    "    model.add(keras.layers.GlobalMaxPooling1D())\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(y.shape[1], activation='softmax')) #第一个参数units: 全连接层输出的维度，即下一层神经元的个数。\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         9004160   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 32)          12320     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 9,016,612\n",
      "Trainable params: 9,016,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features=70345\n",
    "embedding_dims=128\n",
    "filters=32\n",
    "#y_train=np_utils.to_categorical(4)\n",
    "model=base_cnn_model(y_train_labels,max_features,embedding_dims,filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96000 samples, validate on 24000 samples\n",
      "Epoch 1/30\n",
      "96000/96000 [==============================] - 231s 2ms/step - loss: 1.0290 - acc: 0.5327 - val_loss: 0.5861 - val_acc: 0.8195\n",
      "Epoch 2/30\n",
      "96000/96000 [==============================] - 298s 3ms/step - loss: 0.6987 - acc: 0.7193 - val_loss: 0.4613 - val_acc: 0.8587\n",
      "Epoch 3/30\n",
      "96000/96000 [==============================] - 291s 3ms/step - loss: 0.5922 - acc: 0.7806 - val_loss: 0.3964 - val_acc: 0.8727\n",
      "Epoch 4/30\n",
      "96000/96000 [==============================] - 293s 3ms/step - loss: 0.5395 - acc: 0.8011 - val_loss: 0.3808 - val_acc: 0.8802\n",
      "Epoch 5/30\n",
      "96000/96000 [==============================] - 289s 3ms/step - loss: 0.5039 - acc: 0.8141 - val_loss: 0.3805 - val_acc: 0.8765\n",
      "Epoch 6/30\n",
      "96000/96000 [==============================] - 286s 3ms/step - loss: 0.4785 - acc: 0.8219 - val_loss: 0.4020 - val_acc: 0.8734\n",
      "Epoch 7/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.4609 - acc: 0.8275 - val_loss: 0.3762 - val_acc: 0.8778\n",
      "Epoch 8/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.4437 - acc: 0.8340 - val_loss: 0.3747 - val_acc: 0.8765\n",
      "Epoch 9/30\n",
      "96000/96000 [==============================] - 285s 3ms/step - loss: 0.4311 - acc: 0.8390 - val_loss: 0.3689 - val_acc: 0.8814\n",
      "Epoch 10/30\n",
      "96000/96000 [==============================] - 286s 3ms/step - loss: 0.4186 - acc: 0.8436 - val_loss: 0.3905 - val_acc: 0.8762\n",
      "Epoch 11/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.4053 - acc: 0.8481 - val_loss: 0.3856 - val_acc: 0.8782\n",
      "Epoch 12/30\n",
      "96000/96000 [==============================] - 285s 3ms/step - loss: 0.3782 - acc: 0.8602 - val_loss: 0.3903 - val_acc: 0.8789\n",
      "Epoch 13/30\n",
      "96000/96000 [==============================] - 285s 3ms/step - loss: 0.3693 - acc: 0.8627 - val_loss: 0.4052 - val_acc: 0.8773\n",
      "Epoch 14/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.3565 - acc: 0.8672 - val_loss: 0.4073 - val_acc: 0.8761\n",
      "Epoch 15/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.3442 - acc: 0.8760 - val_loss: 0.4144 - val_acc: 0.8728\n",
      "Epoch 16/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.3156 - acc: 0.8870 - val_loss: 0.4223 - val_acc: 0.8765\n",
      "Epoch 17/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.2955 - acc: 0.8966 - val_loss: 0.4402 - val_acc: 0.8728\n",
      "Epoch 18/30\n",
      "96000/96000 [==============================] - 285s 3ms/step - loss: 0.2894 - acc: 0.8976 - val_loss: 0.4377 - val_acc: 0.8705\n",
      "Epoch 19/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.2794 - acc: 0.9013 - val_loss: 0.4600 - val_acc: 0.8701\n",
      "Epoch 20/30\n",
      "96000/96000 [==============================] - 285s 3ms/step - loss: 0.2614 - acc: 0.9096 - val_loss: 0.4620 - val_acc: 0.8682\n",
      "Epoch 21/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.2597 - acc: 0.9110 - val_loss: 0.4959 - val_acc: 0.8716\n",
      "Epoch 22/30\n",
      "96000/96000 [==============================] - 285s 3ms/step - loss: 0.2482 - acc: 0.9152 - val_loss: 0.4987 - val_acc: 0.8691\n",
      "Epoch 23/30\n",
      "96000/96000 [==============================] - 285s 3ms/step - loss: 0.2444 - acc: 0.9162 - val_loss: 0.5189 - val_acc: 0.8658\n",
      "Epoch 24/30\n",
      "96000/96000 [==============================] - 285s 3ms/step - loss: 0.2337 - acc: 0.9215 - val_loss: 0.5409 - val_acc: 0.8644\n",
      "Epoch 25/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.2256 - acc: 0.9228 - val_loss: 0.5618 - val_acc: 0.8676\n",
      "Epoch 26/30\n",
      "96000/96000 [==============================] - 285s 3ms/step - loss: 0.2199 - acc: 0.9253 - val_loss: 0.5670 - val_acc: 0.8611\n",
      "Epoch 27/30\n",
      "96000/96000 [==============================] - 284s 3ms/step - loss: 0.2132 - acc: 0.9284 - val_loss: 0.5560 - val_acc: 0.8660\n",
      "Epoch 28/30\n",
      "96000/96000 [==============================] - 287s 3ms/step - loss: 0.2016 - acc: 0.9324 - val_loss: 0.6060 - val_acc: 0.8622\n",
      "Epoch 29/30\n",
      "96000/96000 [==============================] - 287s 3ms/step - loss: 0.1960 - acc: 0.9341 - val_loss: 0.6032 - val_acc: 0.8620\n",
      "Epoch 30/30\n",
      "96000/96000 [==============================] - 286s 3ms/step - loss: 0.1924 - acc: 0.9352 - val_loss: 0.6137 - val_acc: 0.8597\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x,\n",
    "                    y_train_labels,\n",
    "                    validation_split=0.2,\n",
    "                    batch_size=64,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600/7600 [==============================] - 2s 206us/step\n",
      "[0.5340392661408374, 0.8772368421052632]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_x, y_test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
